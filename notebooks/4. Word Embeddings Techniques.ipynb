{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sacremoses import MosesTokenizer\n",
    "import Levenshtein\n",
    "import spacy\n",
    "import nltk\n",
    "import pickle\n",
    "import urllib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "from gensim import models\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "RESOURCES_DIR = Path(\"C:/Users/Antonio/PycharmProjects/simpleTextCLEF/resources\")\n",
    "DATASETS_PATH = RESOURCES_DIR / \"datasets\"\n",
    "WORD_EMBEDDINGS_NAME = \"glove.42B.300d\"\n",
    "DUMPS_DIR = RESOURCES_DIR / \"DUMPS\"\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def convert_glove_to_word2vec(path_glove):\n",
    "    glove_file = datapath(path_glove)\n",
    "    tmp_file = get_tmpfile(DUMPS_DIR / \"test_word2vec.txt\")\n",
    "    glove2word2vec(glove_file, tmp_file)\n",
    "    model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def ControlDivisionByZero(numerator, denominator):\n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "class WordRankRatio():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tokenizer = MosesTokenizer(lang='en')\n",
    "        self.word2rank = self._get_word2rank()\n",
    "        self.length_rank = len(self.word2rank)\n",
    "\n",
    "    def calculate_ratio(self, simple_text, original_text):\n",
    "\n",
    "        result_ratio = round(min(ControlDivisionByZero(self.get_lexical_complexity_score(simple_text),\n",
    "                                                       self.get_lexical_complexity_score(original_text)),\n",
    "                                 2), 2)\n",
    "\n",
    "        return result_ratio\n",
    "\n",
    "    def get_lexical_complexity_score(self, sentence):\n",
    "\n",
    "        words = self.tokenizer.tokenize(self._remove_stopwords(self._remove_punctuation(sentence)))\n",
    "        words = [word for word in words if word in self.word2rank]\n",
    "        if len(words) == 0:\n",
    "            return np.log(1 + self.length_rank)\n",
    "        return np.quantile([self._get_rank(word) for word in words], 0.25)\n",
    "\n",
    "    def _remove_punctuation(self, text):\n",
    "        return ' '.join([word for word in self.tokenizer.tokenize(text) if not self._is_punctuation(word)])\n",
    "\n",
    "    def _remove_stopwords(self, text):\n",
    "        return ' '.join([w for w in self.tokenizer.tokenize(text) if w.lower() not in stopwords])\n",
    "\n",
    "    def _is_punctuation(self, word):\n",
    "        return ''.join([char for char in word if char not in punctuation]) == ''\n",
    "\n",
    "    def _get_rank(self, word):\n",
    "        rank = self.word2rank.get(word, self.length_rank)\n",
    "        return np.log(1 + rank)\n",
    "\n",
    "    def _get_word2rank(self, vocab_size=np.inf):\n",
    "        model_filepath = DUMPS_DIR / f\"{WORD_EMBEDDINGS_NAME}.pk\"\n",
    "        if model_filepath.exists():\n",
    "            with open(model_filepath, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            return model\n",
    "        else:\n",
    "            print(\"Downloading glove.42B.300d ...\")\n",
    "            self._download_glove(model_name='glove.42B.300d', dest_dir=str(DUMPS_DIR))\n",
    "            print(\"Preprocessing word2rank...\")\n",
    "            DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "            WORD_EMBEDDINGS_PATH = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "            lines_generator = self._yield_lines(WORD_EMBEDDINGS_PATH)\n",
    "            word2rank = {}\n",
    "            # next(lines_generator)\n",
    "            for i, line in enumerate(lines_generator):\n",
    "                if i >= vocab_size: break\n",
    "                word = line.split(' ')[0]\n",
    "                word2rank[word] = i\n",
    "\n",
    "            pickle.dump(word2rank, open(model_filepath, 'wb'))\n",
    "            txt_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "            zip_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.zip'\n",
    "            if txt_file.exists(): txt_file.unlink()\n",
    "            if zip_file.exists(): zip_file.unlink()\n",
    "            return word2rank\n",
    "\n",
    "    def _download_glove(self, model_name, dest_dir):\n",
    "        url = ''\n",
    "        if model_name == 'glove.6B':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "        elif model_name == 'glove.42B.300d':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.42B.300d.zip'\n",
    "        elif model_name == 'glove.840B.300d':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "        elif model_name == 'glove.twitter.27B':\n",
    "            url = 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n",
    "        else:\n",
    "            possible_values = ['glove.6B', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B']\n",
    "            raise ValueError('Unknown model_name. Possible values are {}'.format(possible_values))\n",
    "        file_path = self._download_url(url, dest_dir)\n",
    "        out_filepath = Path(file_path)\n",
    "        out_filepath = out_filepath.parent / f'{out_filepath.stem}.txt'\n",
    "        # print(out_filepath, out_filepath.exists())\n",
    "        if not out_filepath.exists():\n",
    "            print(\"Extracting: \", Path(file_path).name)\n",
    "            self._unzip(file_path, dest_dir)\n",
    "\n",
    "    def _yield_lines(self, filepath):\n",
    "        filepath = Path(filepath)\n",
    "        with filepath.open('r', encoding=\"latin-1\") as f:\n",
    "            for line in f:\n",
    "                yield line.rstrip()\n",
    "\n",
    "    def _download_url(self, url, output_path):\n",
    "        name = url.split('/')[-1]\n",
    "        file_path = f'{output_path}/{name}'\n",
    "        if not Path(file_path).exists():\n",
    "            with tqdm(unit='B', unit_scale=True, leave=True, miniters=1,\n",
    "                      desc=name) as t:  # all optional kwargs\n",
    "                urllib.request.urlretrieve(url, filename=file_path, reporthook=self._download_report_hook(t), data=None)\n",
    "        return file_path\n",
    "\n",
    "    def _unzip(self, file_path, dest_dir=None):\n",
    "        if dest_dir is None:\n",
    "            dest_dir = os.path.dirname(file_path)\n",
    "        if file_path.endswith('.zip'):\n",
    "            with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(dest_dir)\n",
    "        elif file_path.endswith(\"tar.gz\") or file_path.endswith(\"tgz\"):\n",
    "            tar = tarfile.open(file_path, \"r:gz\")\n",
    "            tar.extractall(dest_dir)\n",
    "            tar.close()\n",
    "        elif file_path.endswith(\"tar\"):\n",
    "            tar = tarfile.open(file_path, \"r:\")\n",
    "            tar.extractall(dest_dir)\n",
    "            tar.close()\n",
    "\n",
    "    def _download_report_hook(self, t):\n",
    "        last_b = [0]\n",
    "\n",
    "        def inner(b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                t.total = tsize\n",
    "            t.update((b - last_b[0]) * bsize)\n",
    "            last_b[0] = b\n",
    "\n",
    "        return inner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "complex_sentence = \"We introduce Ignition: an end-to-end neural network architecture for training unconstrained self-driving vehicles in simulated environments.\"\n",
    "simple_sentence = \"Ignition is a neural network for training unconstrained self-driving vehicles in simulated environments.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "wordRank = WordRankRatio()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "7.896465224107381"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordRank.get_lexical_complexity_score(complex_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "7.4619136612316534"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordRank.get_lexical_complexity_score(simple_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "dump_path = DUMPS_DIR / \"PubMed-w2v.bin\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "w2v_model = models.KeyedVectors.load_word2vec_format(dump_path, binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "<gensim.models.keyedvectors.KeyedVectors at 0x1e485a2e940>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "[('hypertrophies', 0.7315719723701477),\n ('pressure-overload', 0.711495041847229),\n ('hyperthrophy', 0.7106752991676331),\n ('Pressure-overload', 0.7056758999824524),\n ('pressure-overload-induced', 0.6775561571121216),\n ('LVH', 0.6729657649993896),\n ('hypertrophy/hypertension', 0.6670820116996765),\n ('RVH', 0.664328396320343),\n ('hypertrabeculation', 0.6639715433120728),\n ('hypocontractility', 0.652051568031311)]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"hypertrophy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_8580\\2384134400.py:4: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, tmp_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<gensim.models.keyedvectors.KeyedVectors at 0x1e485ae9130>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#glove_embeddings = convert_glove_to_word2vec(DUMPS_DIR / \"glove.42B.300d.txt\")\n",
    "#glove_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "glove_path = DUMPS_DIR / \"test_word2vec.txt\"\n",
    "glove_model  =  models.KeyedVectors.load_word2vec_format(glove_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "131569"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.key_to_index[\"self-driving\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "2174408"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.key_to_index[\"self-driving\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_index() missing 1 required positional argument: 'key'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [90]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mglove_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: get_index() missing 1 required positional argument: 'key'"
     ]
    }
   ],
   "source": [
    "glove_model.get_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "2351706"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "1917494"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "([('Perceptron', 0.7978965044021606),\n  ('Perceptrons', 0.7940062284469604),\n  ('BP-ANN', 0.759662389755249),\n  ('Backpropagation', 0.7585924863815308),\n  ('WNN', 0.7571470737457275),\n  ('BPNN', 0.7490246295928955),\n  ('RBFNN', 0.7455959320068359),\n  ('TDNN', 0.7431018352508545),\n  ('MLPN', 0.7379424571990967),\n  ('ANN-MLP', 0.7352424263954163)],\n 475773,\n 211130)"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"Multi-Layer\"), w2v_model.get_index(\"Multi-Layer\"),  w2v_model.get_index(\"Perceptron\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'Multi-Layer' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [120]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mglove_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmost_similar\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMulti-Layer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m, glove_model\u001B[38;5;241m.\u001B[39mget_index(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate-of-the-art\u001B[39m\u001B[38;5;124m\"\u001B[39m), glove_model\u001B[38;5;241m.\u001B[39mget_index(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minnovative\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\users\\antonio\\pycharmprojects\\simpletextclef\\venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:773\u001B[0m, in \u001B[0;36mKeyedVectors.most_similar\u001B[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001B[0m\n\u001B[0;32m    771\u001B[0m     mean\u001B[38;5;241m.\u001B[39mappend(weight \u001B[38;5;241m*\u001B[39m key)\n\u001B[0;32m    772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 773\u001B[0m     mean\u001B[38;5;241m.\u001B[39mappend(weight \u001B[38;5;241m*\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[0;32m    774\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_index_for(key):\n\u001B[0;32m    775\u001B[0m         all_keys\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_index(key))\n",
      "File \u001B[1;32mc:\\users\\antonio\\pycharmprojects\\simpletextclef\\venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:438\u001B[0m, in \u001B[0;36mKeyedVectors.get_vector\u001B[1;34m(self, key, norm)\u001B[0m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_vector\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    415\u001B[0m     \u001B[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001B[39;00m\n\u001B[0;32m    416\u001B[0m \n\u001B[0;32m    417\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    436\u001B[0m \n\u001B[0;32m    437\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 438\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m norm:\n\u001B[0;32m    440\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_norms()\n",
      "File \u001B[1;32mc:\\users\\antonio\\pycharmprojects\\simpletextclef\\venv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:412\u001B[0m, in \u001B[0;36mKeyedVectors.get_index\u001B[1;34m(self, key, default)\u001B[0m\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n\u001B[0;32m    411\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 412\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not present\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Key 'Multi-Layer' not present\""
     ]
    }
   ],
   "source": [
    "glove_model.most_similar(\"Multi-Layer\"), glove_model.get_index(\"Multi-Layer\"), glove_model.get_index(\"innovative\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}