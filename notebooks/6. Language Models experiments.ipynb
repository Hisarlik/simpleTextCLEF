{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from string import punctuation\n",
    "import transformers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "model = transformers.AutoModelWithLMHead.from_pretrained('lordtt13/COVID-SciBERT')\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('lordtt13/COVID-SciBERT')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "('[MASK]', 104)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token, tokenizer.mask_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "'Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning.'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning.\"\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "23"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split = text.split(\" \")\n",
    "sentence_length = len(sentence_split)\n",
    "sentence_length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_id = random.randint(0, sentence_length)\n",
    "mask_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "'on'"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2mask = sentence_split[1]\n",
    "word2mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "'on'"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2mask = word2mask.replace(\",\",\"\")\n",
    "word2mask = word2mask.replace(\".\",\"\")\n",
    "word2mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "sentence_split[mask_id] = \"[MASK]\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "'Based on the Inception-v3 architecture, our system performs better in terms of [MASK] complexity and accuracy than many existing models for imitation learning.'"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_final = \" \".join(sentence_split)\n",
    "sentence_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  102,   791,   191,   111,   306,  2613,   110,   579,   171, 30138,\n          3652,   422,   580,   429,  8629,  1883,   121,  1615,   131,   104,\n          3480,   137,  2683,   506,  1164,   199, 30109, 31862,  1262,   168,\n         27248,  1904,   205,   103]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sentence_final, return_tensors=\"pt\")\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] based on the inc ##epti ##on - v ##3 architecture , our system performs better in terms of [MASK] complexity and accuracy than many ex ##i sting models for imitation learning . [SEP] \n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "for word in inputs['input_ids'][0]:\n",
    "    sentence += tokenizer.decode([word]) + \" \"\n",
    "print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "token_logits = model(**inputs).logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 34, 31941])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([19])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "mask_token_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "mask_token_logits = token_logits[0,mask_token_index,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "[3989,\n 532,\n 2208,\n 2307,\n 11055,\n 2411,\n 437,\n 2848,\n 1904,\n 2318,\n 12185,\n 3937,\n 3480,\n 2188,\n 453,\n 655,\n 3838,\n 4197,\n 6402,\n 1150]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_tokens = torch.topk(mask_token_logits,20,dim=1).indices[0].tolist()\n",
    "top_5_tokens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computational\n",
      "time\n",
      "training\n",
      "processing\n",
      "decoding\n",
      "memory\n",
      "model\n",
      "implementation\n",
      "learning\n",
      "parameter\n",
      "runtime\n",
      "computation\n",
      "complexity\n",
      "task\n",
      "data\n",
      "both\n",
      "prediction\n",
      "storage\n",
      "compression\n",
      "performance\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "    print(tokenizer.decode([token]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of computational complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of time complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of training complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of decoding complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of memory complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of model complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of implementation complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of learning complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of parameter complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of runtime complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of computation complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of complexity complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of task complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of data complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of both complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of prediction complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of storage complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of compression complexity and accuracy than many existing models for imitation learning.'\n",
      "'>>> Based on the Inception-v3 architecture, our system performs better in terms of performance complexity and accuracy than many existing models for imitation learning.'\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {sentence_final.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}