{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack.document_store.elasticsearch'; 'haystack.document_store' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoModelForQuestionAnswering\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdocument_store\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01melasticsearch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ElasticsearchDocumentStore\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mretriever\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ElasticsearchRetriever\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mreader\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfarm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FARMReader\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'haystack.document_store.elasticsearch'; 'haystack.document_store' is not a package"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "from transformers import pipeline\n",
    "\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "from haystack.pipeline import Pipeline\n",
    "from haystack.eval import EvalDocuments\n",
    "from haystack import Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subjqa = load_dataset(\"subjqa\", name=\"electronics\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(subjqa[\"train\"][\"answers\"][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_cols = [\"title\", \"question\", \"answers.text\",\n",
    "           \"answers.answer_start\", \"context\"]\n",
    "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
    "sample_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts = {}\n",
    "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n",
    "\n",
    "for q in question_types:\n",
    "    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n",
    "\n",
    "pd.Series(counts).sort_values().plot.barh()\n",
    "plt.title(\"Frequency of Question Types\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizing text for QA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"How much music can this hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
    "file size.\"\"\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Input IDs shape: {inputs.input_ids.size()}\")\n",
    "print(f\"Start logits shape: {start_logits.size()}\")\n",
    "print(f\"End logits shape: {end_logits.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "answer = tokenizer.decode(answer_span)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "pipe(question=question, context=context, topk=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!curl -X GET \"localhost:9200/?pretty\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Return the document embedding for later use with dense retriever\n",
    "document_store = ElasticsearchDocumentStore(return_embedding=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for split, df in dfs.items():\n",
    "    # Exclude duplicate reviews\n",
    "    docs = [{\"text\": row[\"context\"],\n",
    "             \"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\n",
    "                     \"split\": split}}\n",
    "        for _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n",
    "    document_store.write_documents(docs, index=\"document\")\n",
    "\n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "es_retriever = ElasticsearchRetriever(document_store=document_store)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\"\n",
    "retrieved_docs = es_retriever.retrieve(\n",
    "    query=query, top_k=3, filters={\"item_id\":[item_id], \"split\":[\"train\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrieved_docs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrieved_docs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "max_seq_length, doc_stride = 384, 128\n",
    "reader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False,\n",
    "                    max_seq_len=max_seq_length, doc_stride=doc_stride,\n",
    "                    return_no_answer=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(reader.predict_on_texts(question=question, texts=[context], top_k=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, es_retriever)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_answers = 3\n",
    "preds = pipe.run(query=query, top_k_retriever=3, top_k_reader=n_answers,\n",
    "                 filters={\"item_id\": [item_id], \"split\":[\"train\"]})\n",
    "\n",
    "print(f\"Question: {preds['query']} \\n\")\n",
    "for idx in range(n_answers):\n",
    "    print(f\"Answer {idx+1}: {preds['answers'][idx]['answer']}\")\n",
    "    print(f\"Review snippet: ...{preds['answers'][idx]['context']}...\")\n",
    "    print(\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvalRetrieverPipeline:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "        self.eval_retriever = EvalDocuments()\n",
    "        pipe = Pipeline()\n",
    "        pipe.add_node(component=self.retriever, name=\"ESRetriever\",\n",
    "                      inputs=[\"Query\"])\n",
    "        pipe.add_node(component=self.eval_retriever, name=\"EvalRetriever\",\n",
    "                      inputs=[\"ESRetriever\"])\n",
    "        self.pipeline = pipe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = EvalRetrieverPipeline(es_retriever)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i, row in dfs[\"test\"].iterrows():\n",
    "    # Metadata used for filtering in the Retriever\n",
    "    meta = {\"item_id\": row[\"title\"], \"question_id\": row[\"id\"]}\n",
    "    # Populate labels for questions with answers\n",
    "    if len(row[\"answers.text\"]):\n",
    "        for answer in row[\"answers.text\"]:\n",
    "            label = Label(\n",
    "                question=row[\"question\"], answer=answer, id=i, origin=row[\"id\"],\n",
    "                meta=meta, is_correct_answer=True, is_correct_document=True,\n",
    "                no_answer=False)\n",
    "            labels.append(label)\n",
    "    # Populate labels for questions without answers\n",
    "    else:\n",
    "        label = Label(\n",
    "            question=row[\"question\"], answer=\"\", id=i, origin=row[\"id\"],\n",
    "            meta=meta, is_correct_answer=True, is_correct_document=True,\n",
    "            no_answer=True)\n",
    "        labels.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(labels[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "document_store.write_labels(labels, index=\"label\")\n",
    "print(f\"\"\"Loaded {document_store.get_label_count(index=\"label\")} \\\n",
    "question-answer pairs\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}