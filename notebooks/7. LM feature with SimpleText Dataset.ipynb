{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/antonio/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import transformers\n",
    "import random\n",
    "import transformers\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "nltk.download('averaged_perceptron_tagger')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "RESOURCES_DIR = Path(\"../resources\")\n",
    "DATASETS_PATH = RESOURCES_DIR / \"datasets\"\n",
    "WORD_EMBEDDINGS_NAME = \"glove.42B.300d\"\n",
    "DUMPS_DIR = RESOURCES_DIR / \"DUMPS\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIMPLETEXT_DATASET_PATH = DATASETS_PATH / \"simpleText/task 3\"\n",
    "SIMPLETEXT_TRAIN_PATH = SIMPLETEXT_DATASET_PATH / \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "complex_text = pd.read_csv(SIMPLETEXT_TRAIN_PATH / \"simpleText.train.complex.txt\", header=None, sep=\"\\t\", names=[\"original_text\"])\n",
    "simple_text = pd.read_csv(SIMPLETEXT_TRAIN_PATH / \"simpleText.train.simple.txt\", header=None, sep=\"\\t\",names=[\"simple_text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         original_text  \\\n0    In the modern era of automation and robotics, ...   \n1    With the ever increasing number of unmanned ae...   \n2    Due to guidelines set by the governments regar...   \n3    In an attempt to achieve the above mentioned t...   \n4    Derived from the classic image classification ...   \n..                                                 ...   \n643  Bodybuilders generally train with moderate loa...   \n644  Powerlifters, on the other hand, routinely tra...   \n645  Although both groups are known to display impr...   \n646  It has been shown that many factors mediate th...   \n647  Therefore, the purpose of this paper is twofol...   \n\n                                           simple_text  \n0    Current academic and industrial research is in...  \n1    Drones are increasingly used in the civilian a...  \n2    Governments set guidelines on the operation ce...  \n3    Researchers propose data-driven solutions allo...  \n4    The algorithm, based on the Inception model, d...  \n..                                                 ...  \n643  Bodybuilders train with moderate loads and sho...  \n644  Powerlifters, on the other hand, train with hi...  \n645  Although both groups are known to display impr...  \n646  It has been shown that many factors mediate th...  \n647  Therefore, the purpose of this paper is to rev...  \n\n[648 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>simple_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In the modern era of automation and robotics, ...</td>\n      <td>Current academic and industrial research is in...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>With the ever increasing number of unmanned ae...</td>\n      <td>Drones are increasingly used in the civilian a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Due to guidelines set by the governments regar...</td>\n      <td>Governments set guidelines on the operation ce...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In an attempt to achieve the above mentioned t...</td>\n      <td>Researchers propose data-driven solutions allo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Derived from the classic image classification ...</td>\n      <td>The algorithm, based on the Inception model, d...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>Bodybuilders generally train with moderate loa...</td>\n      <td>Bodybuilders train with moderate loads and sho...</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>Powerlifters, on the other hand, routinely tra...</td>\n      <td>Powerlifters, on the other hand, train with hi...</td>\n    </tr>\n    <tr>\n      <th>645</th>\n      <td>Although both groups are known to display impr...</td>\n      <td>Although both groups are known to display impr...</td>\n    </tr>\n    <tr>\n      <th>646</th>\n      <td>It has been shown that many factors mediate th...</td>\n      <td>It has been shown that many factors mediate th...</td>\n    </tr>\n    <tr>\n      <th>647</th>\n      <td>Therefore, the purpose of this paper is twofol...</td>\n      <td>Therefore, the purpose of this paper is to rev...</td>\n    </tr>\n  </tbody>\n</table>\n<p>648 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_pairs = pd.concat([complex_text, simple_text], axis=1)\n",
    "sentences_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/PycharmProjects/simpleTextCLEF/venv/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelWithLMHead.from_pretrained('lordtt13/COVID-SciBERT')\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('lordtt13/COVID-SciBERT')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "def mask_sentence_prediction(text, topk=tokenizer.vocab_size):\n",
    "    #print(\"----------------------\")\n",
    "    sentence_tokens = [token[0] for token in tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)]\n",
    "    pos_tagging_sentence = pos_tag(sentence_tokens)\n",
    "    #print(pos_tag(sentence_tokens))\n",
    "    #print(len(pos_tagging_sentence))\n",
    "    predictions = []\n",
    "    for i, (word, pos) in enumerate(pos_tagging_sentence):\n",
    "\n",
    "        #print(f\"i:{i}, word:{word}, pos:{pos}\")\n",
    "        if pos in ['NNS', 'NN', 'VBP', 'RB', 'VBG','VBD','JJ','VBN','VB','VBZ','JJS','JJR']:\n",
    "            sentence_masked = sentence_tokens.copy()\n",
    "            sentence_masked[i] = \"[MASK]\"\n",
    "            sentence_final = \" \".join(sentence_masked)\n",
    "            #print(sentence_final)\n",
    "            inputs = tokenizer(sentence_final, return_tensors=\"pt\")\n",
    "            token_logits = model(**inputs).logits\n",
    "            mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "            mask_token_logits = token_logits[0,mask_token_index,:]\n",
    "            top_n_tokens = torch.topk(mask_token_logits,topk,dim=1).indices[0].tolist()\n",
    "            predicted_tokens = [tokenizer.decode([token]) for token in top_n_tokens]\n",
    "            if word in predicted_tokens:\n",
    "                predictions.append(predicted_tokens.index(word))\n",
    "\n",
    "\n",
    "    predictions = [np.log(pred+1) for pred in predictions]\n",
    "    #print(predictions)\n",
    "    if len(predictions) == 0:\n",
    "            return np.log(1 + topk)\n",
    "\n",
    "    value = np.quantile(predictions, 0.75)\n",
    "    return value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "def mask_sentence_prediction(text, topk=10):\n",
    "    sentence_tokens = [token[0] for token in tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)]\n",
    "    #print(pos_tag(sentence_tokens))\n",
    "    pos_tagging_sentence = pos_tag(sentence_tokens)\n",
    "    #print(len(pos_tagging_sentence))\n",
    "    candidates = 0\n",
    "    predictions = 0\n",
    "    for i, (word, pos) in enumerate(pos_tagging_sentence):\n",
    "        #print(f\"i:{i}, word:{word}, pos:{pos}\")\n",
    "        if pos in ['NNS', 'NN', 'VBP', 'RB', 'VBG','VBD']:\n",
    "            candidates +=1\n",
    "            sentence_masked = sentence_tokens.copy()\n",
    "            sentence_masked[i] = \"[MASK]\"\n",
    "            sentence_final = \" \".join(sentence_masked)\n",
    "            #print(sentence_final)\n",
    "            inputs = tokenizer(sentence_final, return_tensors=\"pt\")\n",
    "            token_logits = model(**inputs).logits\n",
    "            mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "            mask_token_logits = token_logits[0,mask_token_index,:]\n",
    "            top_n_tokens = torch.topk(mask_token_logits,topk,dim=1).indices[0].tolist()\n",
    "            predicted_tokens = [tokenizer.decode([token]) for token in top_n_tokens]\n",
    "            if word in predicted_tokens:\n",
    "                predictions +=1\n",
    "\n",
    "    if candidates != 0:\n",
    "        return predictions/candidates\n",
    "    else:\n",
    "        return 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "#mask_sentence_prediction(\"The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "def check_pair_sentence(complex, simple):\n",
    "    complex_feature = mask_sentence_prediction(complex)\n",
    "    simple_feature = mask_sentence_prediction(simple)\n",
    "    #print(f\"Complex feature: {complex_feature}. Simple feature: {simple_feature}\")\n",
    "    if complex_feature !=0:\n",
    "        value = simple_feature/complex_feature\n",
    "    else:\n",
    "        value = 1\n",
    "    if value > 5:\n",
    "        print(f\"Complex feature: {complex_feature}. Simple feature: {simple_feature}\")\n",
    "    return min(value,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "complex = \"The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec.\"\n",
    "simple = \"MAVNet computational efficiency enables the drone to fly up to 6m/sec.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "1.4469237140841469"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pair_sentence(complex, simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex feature: 0.44793986730701374. Simple feature: 3.704265283447313\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i,row in sentences_pairs.iterrows():\n",
    "    value = check_pair_sentence(row['original_text'], row['simple_text'])\n",
    "    results.append(value)\n",
    "    #if i == 100:\n",
    "    #    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(results,label=\"LM\")\n",
    "fig.legend(labels=['LM'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}